{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eventlet\n",
    "import json\n",
    "from flask import Flask, render_template\n",
    "from flask_socketio import SocketIO\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "from PIL import Image\n",
    "#######################################\n",
    "from chatbot import chatbot\n",
    "from chatbot.chatbot import response,classify\n",
    "#######################################\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from random import randrange\n",
    "from facedetect_folder.facedetect import detect_face,reset_keras\n",
    "from keras.models import load_model\n",
    "from statistics import mode\n",
    "from facedetect_folder.utils.datasets import get_labels\n",
    "from facedetect_folder.utils.inference import detect_faces\n",
    "from facedetect_folder.utils.inference import draw_text\n",
    "from facedetect_folder.utils.inference import draw_bounding_box\n",
    "from facedetect_folder.utils.inference import apply_offsets\n",
    "from facedetect_folder.utils.inference import load_detection_model\n",
    "from facedetect_folder.utils.preprocessor import preprocess_input\n",
    "import face_recognition\n",
    "import code_tfpose\n",
    "from code_tfpose import *\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "import tensorflow\n",
    "import gc\n",
    "import pyttsx3\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import record_chatbot\n",
    "from record_chatbot import *\n",
    "#from text_to_speech import text_2_speech\n",
    "#######################################\n",
    "# eventlet.monkey_patch()\n",
    "app = Flask(__name__)\n",
    "socketio = SocketIO(app)\n",
    "@app.route('/')\n",
    "def index():        # set index\n",
    "    return render_template('index.html')\n",
    "##############################################ACTIVE DETECT FACE##################################################\n",
    "@socketio.on('active_face2')\n",
    "def activez_face(json_str):\n",
    "    data = json_str\n",
    "    if data=='active_face':\n",
    "        global emotion_model_path \n",
    "        emotion_model_path = 'facedetect_folder/models/emotion_model.hdf5'\n",
    "        global emotion_labels \n",
    "        emotion_labels = get_labels('fer2013')\n",
    "        global emotion_classifier\n",
    "        emotion_classifier = load_model(emotion_model_path)\n",
    "        global kn_image\n",
    "        global kn_face_encoding_0\n",
    "        global known_face_encodings\n",
    "        known_face_encodings=[]\n",
    "        global known_face_names_0\n",
    "        global known_face_names\n",
    "        known_face_names=[]\n",
    "        \n",
    "        files = [f for f in os.listdir(\"facedetect_folder/faceknow\")]\n",
    "        for i in files:\n",
    "            kn_image=face_recognition.load_image_file(\"facedetect_folder/faceknow/\"+i)\n",
    "            kn_face_encoding_0 = face_recognition.face_encodings(kn_image)[0]\n",
    "            known_face_encodings.append(kn_face_encoding_0)\n",
    "            known_face_names_0=i[:-4]\n",
    "            known_face_names.append(known_face_names_0)\n",
    "        \n",
    "        print(8*'active_face')\n",
    "        repliesmess=\"done_active\"\n",
    "        socketio.emit('done_active_face', data=repliesmess)\n",
    "##############################################ACTIVE DETECT FACE##################################################\n",
    "@socketio.on('publish')     # send mess\n",
    "def handle_publish(json_str):\n",
    "    data = json_str\n",
    "    ##################### (nhớ mở những dòng ở giữa đây)\n",
    "    image_data = cv2.imdecode(np.frombuffer(data, np.uint8), -1)\n",
    "    #####################\n",
    "    #####################\n",
    "    file_send,name,emotion_text=detect_face(image_data,known_face_names,known_face_encodings,emotion_classifier,emotion_labels)\n",
    "    #####################\n",
    "    #####################\n",
    "    socketio.emit('mqtt_message', data=file_send)\n",
    "    # #####################\n",
    "    if (name != 'Unknown'): \n",
    "        check_time=time.time()\n",
    "\n",
    "        socketio.emit('check_time', data=check_time)\n",
    "        socketio.emit('mqtt_message_name', data=name)\n",
    "        socketio.emit('mqtt_message_emotion', data=emotion_text)\n",
    "        # text=\"Hello \"+name+\", I see your mood today \" + emotion_text+\". Would you like to talk with me?\"\n",
    "\n",
    "        # text_2_speech(text)\n",
    "#         socketio.emit('send_audio_file', data=\"../static/audio/ouput_speech.wav\")\n",
    "    # #####################\n",
    "##############################################DEACTIVE DETECT FACE##################################################\n",
    "\n",
    "@socketio.on('deactive_face')\n",
    "def deactive_face(json_str):\n",
    "    data = json_str\n",
    "    if data=='deactive_face':\n",
    "        ######################\n",
    "        sess = get_session()\n",
    "        clear_session()\n",
    "        sess.close()\n",
    "        sess = get_session()\n",
    "\n",
    "        try:\n",
    "            del emotion_model_path\n",
    "            del emotion_labels\n",
    "            del emotion_classifier\n",
    "            del kn_image\n",
    "            del kn_face_encoding\n",
    "            del known_face_encodings\n",
    "            del known_face_names\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "        # use the same config as you used to create the session\n",
    "        config = tensorflow.ConfigProto()\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "        config.gpu_options.visible_device_list = \"0\"\n",
    "        set_session(tensorflow.Session(config=config))\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth=True\n",
    "        sess = tf.Session(config=config)\n",
    "        print(60*'@')\n",
    "        \n",
    "        ######################\n",
    "        repliesmess=\"done_deactive\"\n",
    "        print(repliesmess)\n",
    "        socketio.emit('done_deactive_face', data=repliesmess)\n",
    "\n",
    "\n",
    "##############################################DEACTIVE DETECT FACE##################################################\n",
    "\n",
    "\n",
    "##############################################ACTIVE TRAIN##################################################\n",
    "@socketio.on('active_train')\n",
    "def active_train_zz(json_str):\n",
    "        data = json_str\n",
    "        global action_labels\n",
    "        global my_detector\n",
    "        global multipeople_classifier,multiperson_tracker\n",
    "        # if data=='active_train1':\n",
    "\n",
    "        # ######################\n",
    "                \n",
    "        # action_labels =  ['jump','kick','punch','run','sit','squat','stand','walk','none']\n",
    "        action_labels =  ['none','none','none','none','sit','squat','stand','none','none']\n",
    "        \n",
    "        my_detector = SkeletonDetector(OpenPose_MODEL, image_size)\n",
    "        \n",
    "        multipeople_classifier,multiperson_tracker=multi(LOAD_MODEL_PATH,action_labels)\n",
    "        print(80*'*')\n",
    "        ######################\n",
    "        repliesmess=\"done_active\"\n",
    "        print(repliesmess)\n",
    "        print(80*'*')     \n",
    "        socketio.emit('done_active_train', data='done_active')\n",
    "        socketio.emit('done_select_td', data='4')\n",
    "\n",
    "@socketio.on('publish_train')     # send mess\n",
    "def handle_publish_train(json_str):\n",
    "    data = json_str\n",
    "    ######################\n",
    "    image_data = cv2.imdecode(np.frombuffer(data, np.uint8), -1)\n",
    "    ######################\n",
    "    #*******************************************************************************************************#\n",
    "    #*******************************************************************************************************#\n",
    "    ######################\n",
    "    count_human,label,file_send=code_main(my_detector,multipeople_classifier,multiperson_tracker,image_data)\n",
    "    ######################\n",
    "    #*******************************************************************************************************#\n",
    "    ######################\n",
    "    socketio.emit('mqtt_message', data=file_send)\n",
    "    print(2*'count_human',count_human)\n",
    "    if count_human!=0:\n",
    "        if (label!='none') and (label!='sit'):\n",
    "                socketio.emit('label_human', data=label)\n",
    "        check_time=time.time()\n",
    "        socketio.emit('check_time_train', data=check_time)\n",
    "    if count_human=='none':\n",
    "    #     time.sleep(20)\n",
    "        check_time=time.time()\n",
    "        socketio.emit('check_time_canhbao', data=check_time)\n",
    "        print('GUI CANH BAO KHONG THAY NGUOI GUI CANH BAO')\n",
    "        socketio.emit('send_audio_file', data=\"../static/audio/warning.wav\")\n",
    "\n",
    "##############################################ACTIVE TRAIN##################################################\n",
    "##############################################DEACTIVE DETECT TRAIN##################################################\n",
    "@socketio.on('de_active_train')\n",
    "def deactive_train(json_str):\n",
    "    data = json_str\n",
    "    if data=='deactive_train':\n",
    "        ######################\n",
    "        sess = get_session()\n",
    "        clear_session()\n",
    "        sess.close()\n",
    "        sess = get_session()\n",
    "        try:\n",
    "            del my_detector\n",
    "            del multipeople_classifier\n",
    "            del multiperson_tracker       \n",
    "        except:\n",
    "            pass\n",
    "        print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "        # use the same config as you used to create the session\n",
    "        config = tensorflow.ConfigProto()\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "        config.gpu_options.visible_device_list = \"0\"\n",
    "        set_session(tensorflow.Session(config=config))\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth=True\n",
    "        sess = tf.Session(config=config)\n",
    "        ######################\n",
    "        print(60*'k')\n",
    "        repliesmess=\"done_deactive\"\n",
    "        print(repliesmess)\n",
    "        socketio.emit('done_deactive_train', data=repliesmess)\n",
    "##############################################DEACTIVE DETECT TRAIN##################################################\n",
    "@socketio.on('check_sendmess_spe')\n",
    "def handle_sendmess(json_str):\n",
    "    repliesmess=\"\"\n",
    "    data = json_str\n",
    "    print(\"+++++++++\")\n",
    "    print(data,type(data))\n",
    "    # repliesmess=response(data)\n",
    "    if (data=='blob_blob'):\n",
    "        socketio.emit('replies_sendmess_spe', data='replies2_sendmess_spe')\n",
    "# ######################\n",
    "#########them chat bot tieng anh vao day####################\n",
    "@socketio.on('sendmess')\n",
    "def handle_sendmess(json_str):\n",
    "    repliesmess=\"\"\n",
    "    data = json_str\n",
    "    print(\"+++++++++\")\n",
    "    print(data,type(data))\n",
    "    # repliesmess=response(data)\n",
    "    repliesmess=\"Yes, I have\"\n",
    "    socketio.emit('replieszzz', data=repliesmess)\n",
    "###################### \n",
    "\n",
    "@socketio.on('sendmess_spe')\n",
    "def handle_sendmess_spe(json_str):\n",
    "    repliesmess=\"\"\n",
    "    data = json_str\n",
    "   # print(100*'*')\n",
    "   # print(data,type(data))\n",
    "    try:\n",
    "        os.remove('myfile.wav')\n",
    "    except:\n",
    "        print('removed')\n",
    "    with open('myfile.wav', mode='bx') as f:\n",
    "        f.write(data)\n",
    "    \n",
    "    name=speech_to_speech('myfile.wav')\n",
    "    print(name)\n",
    "    socketio.emit('send_process_speech', data=\"../static/audio/\"+name)    \n",
    "#     socketio.emit('replieszzz', data='Get audio speech')\n",
    "#    socketio.emit('process_speech', data='Get_audio_speech')\n",
    "    \n",
    "######################  \n",
    "\n",
    "@socketio.on('check_point')\n",
    "def process_spe(json_str):\n",
    "    text='You make' + json_str + \"movements.Your score is\"+json_str\n",
    "    name=text_to_speech_1(text)\n",
    "    socketio.emit('send_process_speech', data=\"../static/audio/\"+name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    socketio.run(app,host='0.0.0.0', port=5000,debug=True, keyfile='key.pem', certfile='cert.pem',use_reloader=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
